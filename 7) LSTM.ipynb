{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvMLticFakEq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "VPfo1aFubtHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, LSTM, SimpleRNN"
      ],
      "metadata": {
        "id": "TUS3F5Moal19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# time step만큼 시퀀스 데이터 분석\n",
        "def split_sequence(sequence, step):\n",
        "  x, y = list(), list()\n",
        "\n",
        "  for i in range(len(sequence)):\n",
        "    end_idx = i + step\n",
        "    if end_idx > len(sequence) - 1:\n",
        "      break\n",
        "    \n",
        "    seq_x, seq_y = sequence[i:end_idx], sequence[end_idx]\n",
        "    x.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "    \n",
        "  return np.array(x), np.array(y)\n",
        "\n",
        "# sin 함수 학습 데이터\n",
        "x = [i for i in np.arange(start=-10, stop=10, step=0.1)]\n",
        "train_y = [np.sin(i) for i in x]\n",
        "\n",
        "# 하이퍼파라미터\n",
        "n_timesteps = 15\n",
        "n_features = 1\n",
        "\n",
        "# 시퀀스 나누기\n",
        "# train_x.shape => (samples, timesteps)\n",
        "# train_y.shape => (samples)\n",
        "train_x, train_y = split_sequence(train_y, step=n_timesteps)\n",
        "print(\"shape x:{} / y:{}\".format(train_x.shape, train_y.shape))\n",
        "\n",
        "# RNN 입력 벡터 크기를 맞추기 위해 벡터 차원 크기 변경\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], n_features)\n",
        "print(\"train_x.shape = {}\".format(train_x.shape))\n",
        "print(\"train_y.shape = {}\".format(train_y.shape))\n",
        "\n",
        "# LSTM 모델 정의\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=10,\n",
        "                    return_sequences=False,\n",
        "                    input_shape=(n_timesteps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# 모델 학습\n",
        "np.random.seed(0)\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='loss',\n",
        "    patience=5,\n",
        "    mode='auto')\n",
        "history = model.fit(train_x, train_y, epochs=1000, callbacks=[early_stopping])\n",
        "\n",
        "# loss 그래프 생성\n",
        "plt.plot(history.history['loss'], label=\"loss\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()\n",
        "\n",
        "# 테스트 데이터셋 생성\n",
        "test_x = np.arange(10, 20, 0.1)\n",
        "calc_y = np.cos(test_x) # 테스트 정답 데이터\n",
        "\n",
        "# RNN 모델 예측 및 로그 저장\n",
        "test_y = calc_y[:n_timesteps]\n",
        "for i in range(len(test_x) - n_timesteps):\n",
        "  net_input = test_y[i : i + n_timesteps]\n",
        "  net_input = net_input.reshape((1, n_timesteps, n_features))\n",
        "  train_y = model.predict(net_input, verbose=0)\n",
        "  print(test_y.shape, train_y.shape, i, i + n_timesteps)\n",
        "  test_y = np.append(test_y, train_y)\n",
        "\n",
        "# 예측 결과 그레프 그리기\n",
        "plt.plot(test_x, calc_y, label=\"ground truth\", color=\"orange\")\n",
        "plt.plot(test_x, test_y, label=\"predictions\", color=\"blue\")\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.ylim(-2, 2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OKi4wDWZbKWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 양방향 LSTM"
      ],
      "metadata": {
        "id": "6mvxN5oHbwf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import random\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, Dense, LSTM, TimeDistributed"
      ],
      "metadata": {
        "id": "9Htd245ybLHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시퀀스 생성\n",
        "def get_sequence(n_timesteps):\n",
        "  # 0 ~ 1 사이의 랜덤 시퀀스 생성\n",
        "  X = np.array([random() for _ in range(n_timesteps)])\n",
        "\n",
        "  # 클래스 분류 기준\n",
        "  limit = n_timesteps / 4.0\n",
        "\n",
        "  # 누적합 시퀀스에서 클래스 결정\n",
        "  # 누적합 항목이 limit보다 작은 경우 0. 아닌 경우 1로 분류\n",
        "  y = np.array([0 if x < limit else 1 for x in np.cumsum(X)])\n",
        "  \n",
        "  # LSTM 입력을 위해 3차원 텐서 형태로 변경\n",
        "  X = X.reshape(1, n_timesteps, 1)\n",
        "  y = y.reshape(1, n_timesteps, 1)\n",
        "  return X, y\n",
        "\n",
        "# 하이퍼 파라미터 정의\n",
        "n_units = 20\n",
        "n_timesteps = 4\n",
        "\n",
        "# 양방향 LSTM 모델 정의\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(n_units, return_sequences=True, input_shape=(n_timesteps, 1))))\n",
        "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "# 에포크마다 학습 데이터를 생성하여 학습\n",
        "for epoch in range(1000):\n",
        "  X, y = get_sequence(n_timesteps)\n",
        "  model.fit(X, y, epochs=1, batch_size=1, verbose=2)\n",
        "\n",
        "X, y = get_sequence(n_timesteps)\n",
        "\n",
        "y_prob = model.predict(X, verbose=0)\n",
        "y_pred = y_prob.argmax(axis=-1)\n",
        "\n",
        "for i in range(n_timesteps):\n",
        "  print(\"실제값 : \", y[0, i], \"예측값 : \", y_pred[0, i])\n"
      ],
      "metadata": {
        "id": "0tvATYCJb8zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "llHoKfmrdaz2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}