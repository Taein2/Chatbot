{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2) Embedding.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOqfnriV5jWHPbuJNEl8Dpv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taein2/Chatbot/blob/master/2)_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0iunbJ0xRmb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "id": "gOU118KfxnoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Komoran\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9zxBH7FCxZ8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# one-hot encoding "
      ],
      "metadata": {
        "id": "8ocAx5ctygSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "komoran = Komoran()\n",
        "text = \"오늘 날씨는 구름이 많아요.\"\n",
        "\n",
        "#  명사만 추출\n",
        "nouns = komoran.nouns(text)\n",
        "print(nouns)\n",
        "\n",
        "# 단어 사전 구축 및 단어별 인덱스 부여\n",
        "dics = {}\n",
        "for word in nouns:\n",
        "  if word not in dics.keys():\n",
        "    dics[word] = len(dics)\n",
        "print(dics)\n",
        "\n",
        "# one-hot encoding \n",
        "nb_class = len(dics)\n",
        "targets = list(dics.values())\n",
        "one_hot_targets = np.eye(nb_class)[targets]\n",
        "print(one_hot_targets)"
      ],
      "metadata": {
        "id": "k9it-VfxxkKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec"
      ],
      "metadata": {
        "id": "IOEVI_LAyirs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from konlpy.tag import Komoran\n",
        "import time"
      ],
      "metadata": {
        "id": "qoPj6qp8yK24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 네이버 영화 리뷰 데이터 읽어옴\n",
        "def read_review_data(filename):\n",
        "  with open(filename, 'r', errors='replace') as f:\n",
        "    data = [line.split('\\t') for line in f.read().splitlines()]\n",
        "    data = data[1:] # 헤더 제거\n",
        "  return data\n",
        "\n",
        "# 학습 시간 측정\n",
        "start = time.time()\n",
        "\n",
        "# 리뷰 파일 읽어오기\n",
        "print('1) 말뭉치 데이터 읽기 시작')\n",
        "review_data = read_review_data('/content/drive/MyDrive/Colab Notebooks/챗봇/ratings.txt')\n",
        "print(len(review_data)) # 리뷰 데이터 전체 개수\n",
        "print('1) 말뭉치 데이터 읽기 완료 : ',time.time() - start)\n",
        "\n",
        "# 문장 단위로 명사만 추출해 학습 입력 데이터로 만듦\n",
        "print('2) 형태소에서 명사만 추출 시작')\n",
        "komoran = Komoran()\n",
        "docs = [komoran.nouns(sentence[1]) for sentence in review_data]\n",
        "print('2) 형태소에서 명사만 추출 완료 : ', time.time() - start)\n",
        "\n",
        "# Word2Vec 모델 학습\n",
        "print('3) Word2Vec 모델 학습 시작')\n",
        "model = Word2Vec(sentences = docs, size = 200, window = 4, hs = 1, min_count = 2, sg = 1)\n",
        "print('3) Word2Vec 모델 학습 완료 : ', time.time() - start)\n",
        "\n",
        "# 모델 저장\n",
        "print('4) 학습된 모델 저장 시작')\n",
        "model.save('nvmc.model')\n",
        "print('4) 학습된 모델 저장 완료 : ', time.time() - start)\n",
        "\n",
        "# 학습된 말뭉치 수, 코퍼스 내 전체 단어 수\n",
        "print(\"corpus_count : \", model.corpus_count)\n",
        "print(\"corpus_total_words : \", model.corpus_total_words)"
      ],
      "metadata": {
        "id": "xYjfPpxxyryx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 로딩\n",
        "model = Word2Vec.load('nvmc.model')\n",
        "print(\"corpus_total_words : \", model.corpus_total_words)\n",
        "\n",
        "# '사랑'이란 단어로 생성한 단어 임베딩 벡터\n",
        "print('사랑 : ', model.wv['사랑'])\n",
        "\n",
        "# 단어 유사도 계산\n",
        "print(\"일요일 & 월요일\\t\", model.wv.similarity(w1='일요일', w2='월요일'))\n",
        "print(\"안성기 & 배우\\t\", model.wv.similarity(w1='안성기', w2='배우'))\n",
        "print(\"대기업 & 삼성\\t\", model.wv.similarity(w1='대기업', w2='삼성'))\n",
        "print(\"일요일 & 삼성\\t\", model.wv.similarity(w1='일요일', w2='삼성'))\n",
        "print(\"히어로 & 삼성\\t\", model.wv.similarity(w1='히어로', w2='삼성'))\n",
        "\n",
        "# 가장 유사한 단어 추출\n",
        "print(model.wv.most_similar(\"안성기\", topn=5))\n",
        "print(model.wv.most_similar(\"시리즈\", topn=5))"
      ],
      "metadata": {
        "id": "b46iTae90MWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rp-SGZ2MutYd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}